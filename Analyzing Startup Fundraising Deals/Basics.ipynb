{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analyzing Startup Fundraisin Deals from Crunchbase\n",
    "In this quick data engineering project, some of the techniques will be practiced to get a basic foundation on analyzing startup investments from Crunchbase.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Every year, thousands of startup companies raise financing from investors. Each time a startup raises money, we refer to the event as a fundraising round. Crunchbase is a website that crowdsources information on the fundraising rounds of many startups. The Crunchbase user community submits, edits, and maintains most of the information in Crunchbase.\n",
    "\n",
    "In return, Crunchbase makes the data available through a Web application and a fee-based API. Before Crunchbase switched to the paid API model, multiple groups crawled the site and released the data online. Because the information on the startups and their fundraising rounds is always changing, the data set we'll be using isn't completely up to date.\n",
    "\n",
    "That being said, we will use an arbitrary cut off date for the data of October 2013. The dataset can be found here: https://github.com/datahoarder/crunchbase-october-2013/blob/master/crunchbase-investments.csv.\n",
    "\n",
    "We will mainly work with data engineering and different memory constraints here. For more data analysis or data science type projects, they can be found in the appropriate Github repos. We assume that we only have 10 megabytes of available memory. While crunchbase-investments.csv consumes 10.3 megabytes of disk space, we know that pandas often requires 4 to 6 times amount of space in memory as the file does on disk (especially when there's many string columns), so keep this in mind!\n",
    "\n",
    "Let's first get familiar with some columns and chunks, using 5000 rows per chunk (this is much less than 10 mb of memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get pandas and set columns to avoid truncating\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 99\n",
    "\n",
    "# set the reader to a chunk size of 5000\n",
    "chunk_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_country_code          1\n",
       "company_name                  1\n",
       "company_permalink             1\n",
       "company_region                1\n",
       "investor_region               2\n",
       "investor_permalink            2\n",
       "investor_name                 2\n",
       "funded_quarter                3\n",
       "funded_at                     3\n",
       "funded_month                  3\n",
       "funded_year                   3\n",
       "funding_round_type            3\n",
       "company_state_code          492\n",
       "company_city                533\n",
       "company_category_code       643\n",
       "raised_amount_usd          3599\n",
       "investor_country_code     12001\n",
       "investor_city             12480\n",
       "investor_state_code       16809\n",
       "investor_category_code    50427\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create my_list\n",
    "mv_list = []\n",
    "\n",
    "# for each chunk get the nulls \n",
    "for chunk in chunk_iter:\n",
    "    mv_list.append(chunk.isnull().sum())\n",
    "    \n",
    "# add it onto the df and get uniques\n",
    "combined_mv_vc = pd.concat(mv_list)\n",
    "unique_combined_mv_vc = combined_mv_vc.groupby(combined_mv_vc.index).sum()\n",
    "unique_combined_mv_vc.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_permalink         4057788\n",
       "company_name              3591326\n",
       "company_category_code     3421104\n",
       "company_country_code      3172176\n",
       "company_state_code        3106051\n",
       "company_region            3411585\n",
       "company_city              3505926\n",
       "investor_permalink        4980548\n",
       "investor_name             3915666\n",
       "investor_category_code     622424\n",
       "investor_country_code     2647292\n",
       "investor_state_code       2476607\n",
       "investor_region           3396281\n",
       "investor_city             2885083\n",
       "funding_round_type        3410707\n",
       "funded_at                 3542185\n",
       "funded_month              3383584\n",
       "funded_quarter            3383584\n",
       "funded_year                422960\n",
       "raised_amount_usd          422960\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re read\n",
    "chunk_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding='ISO-8859-1')\n",
    "\n",
    "# counter for memory footprint\n",
    "counter = 0\n",
    "\n",
    "# make a series for memory fp\n",
    "series_memory_fp = pd.Series()\n",
    "\n",
    "# for each chunk add onto the series\n",
    "for chunk in chunk_iter:\n",
    "    if counter == 0:\n",
    "        series_memory_fp = chunk.memory_usage(deep=True)\n",
    "    else:\n",
    "        series_memory_fp += chunk.memory_usage(deep=True)\n",
    "    counter += 1\n",
    "\n",
    "# drop memory footprint calculation for the index and display\n",
    "series_memory_fp = series_memory_fp.drop('Index')\n",
    "series_memory_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.9876070022583"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the total memory fp in mb\n",
    "series_memory_fp.sum() / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_country_code          1\n",
       "company_name                  1\n",
       "company_permalink             1\n",
       "company_region                1\n",
       "investor_region               2\n",
       "investor_permalink            2\n",
       "investor_name                 2\n",
       "funded_quarter                3\n",
       "funded_at                     3\n",
       "funded_month                  3\n",
       "funded_year                   3\n",
       "funding_round_type            3\n",
       "company_state_code          492\n",
       "company_city                533\n",
       "company_category_code       643\n",
       "raised_amount_usd          3599\n",
       "investor_country_code     12001\n",
       "investor_city             12480\n",
       "investor_state_code       16809\n",
       "investor_category_code    50427\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display previous unique values for analysis\n",
    "unique_combined_mv_vc.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Index.tolist of Index(['company_name', 'company_category_code', 'company_country_code',\n",
       "       'company_state_code', 'company_region', 'company_city', 'investor_name',\n",
       "       'investor_country_code', 'investor_state_code', 'investor_region',\n",
       "       'investor_city', 'funding_round_type', 'funded_at', 'funded_month',\n",
       "       'funded_quarter', 'funded_year', 'raised_amount_usd'],\n",
       "      dtype='object')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop columns representing URL's or containing way too many missing values (>90% missing)\n",
    "drop_cols = ['investor_permalink', 'company_permalink', 'investor_category_code']\n",
    "keep_cols = chunk.columns.drop(drop_cols)\n",
    "\n",
    "# show keep list\n",
    "keep_cols.tolist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did quite a bit already figuring out the memory footprint that the data holsd as well as figuring out which columns are and are not useful for analysis because of nulls. Next we can select some data types..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Data Types\n",
    "Let's first determine which columns shift types across chunks. Note that we only lay the groundwork for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dict for col types\n",
    "# key: column name \n",
    "# value: List of types\n",
    "col_types = {}\n",
    "\n",
    "# re read\n",
    "chunk_iter = pd.read_csv('crunchbase-investments.csv', chunksize=5000, encoding='ISO-8859-1', usecols=keep_cols)\n",
    "\n",
    "# for each chunk append col type\n",
    "for chunk in chunk_iter:\n",
    "    for col in chunk.columns:\n",
    "        if col not in col_types:\n",
    "            col_types[col] = [str(chunk.dtypes[col])]\n",
    "        else:\n",
    "            col_types[col].append(str(chunk.dtypes[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_category_code': {'object'},\n",
       " 'company_city': {'object'},\n",
       " 'company_country_code': {'object'},\n",
       " 'company_name': {'object'},\n",
       " 'company_region': {'object'},\n",
       " 'company_state_code': {'object'},\n",
       " 'funded_at': {'object'},\n",
       " 'funded_month': {'object'},\n",
       " 'funded_quarter': {'object'},\n",
       " 'funded_year': {'float64', 'int64'},\n",
       " 'funding_round_type': {'object'},\n",
       " 'investor_city': {'float64', 'object'},\n",
       " 'investor_country_code': {'float64', 'object'},\n",
       " 'investor_name': {'object'},\n",
       " 'investor_region': {'object'},\n",
       " 'investor_state_code': {'float64', 'object'},\n",
       " 'raised_amount_usd': {'float64'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique col types dict\n",
    "uniq_col_types = {}\n",
    "\n",
    "# for each pair in col types turn it into a set\n",
    "for k,v in col_types.items():\n",
    "    uniq_col_types[k] = set(col_types[k])\n",
    "    \n",
    "# see uniques\n",
    "uniq_col_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_category_code</th>\n",
       "      <th>company_country_code</th>\n",
       "      <th>company_state_code</th>\n",
       "      <th>company_region</th>\n",
       "      <th>company_city</th>\n",
       "      <th>investor_name</th>\n",
       "      <th>investor_country_code</th>\n",
       "      <th>investor_state_code</th>\n",
       "      <th>investor_region</th>\n",
       "      <th>investor_city</th>\n",
       "      <th>funding_round_type</th>\n",
       "      <th>funded_at</th>\n",
       "      <th>funded_month</th>\n",
       "      <th>funded_quarter</th>\n",
       "      <th>funded_year</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>NuORDER</td>\n",
       "      <td>fashion</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>West Hollywood</td>\n",
       "      <td>Mortimer Singer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>series-a</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>2012-10</td>\n",
       "      <td>2012-Q4</td>\n",
       "      <td>2012</td>\n",
       "      <td>3060000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>ChaCha</td>\n",
       "      <td>advertising</td>\n",
       "      <td>USA</td>\n",
       "      <td>IN</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Carmel</td>\n",
       "      <td>Morton Meyerson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>series-b</td>\n",
       "      <td>2007-10-01</td>\n",
       "      <td>2007-10</td>\n",
       "      <td>2007-Q4</td>\n",
       "      <td>2007</td>\n",
       "      <td>12000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>Binfire</td>\n",
       "      <td>software</td>\n",
       "      <td>USA</td>\n",
       "      <td>FL</td>\n",
       "      <td>Bocat Raton</td>\n",
       "      <td>Bocat Raton</td>\n",
       "      <td>Moshe Ariel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angel</td>\n",
       "      <td>2008-04-18</td>\n",
       "      <td>2008-04</td>\n",
       "      <td>2008-Q2</td>\n",
       "      <td>2008</td>\n",
       "      <td>500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>Binfire</td>\n",
       "      <td>software</td>\n",
       "      <td>USA</td>\n",
       "      <td>FL</td>\n",
       "      <td>Bocat Raton</td>\n",
       "      <td>Bocat Raton</td>\n",
       "      <td>Moshe Ariel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angel</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01</td>\n",
       "      <td>2010-Q1</td>\n",
       "      <td>2010</td>\n",
       "      <td>750000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50004</th>\n",
       "      <td>Unified Color</td>\n",
       "      <td>software</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>SF Bay</td>\n",
       "      <td>South San Frnacisco</td>\n",
       "      <td>Mr. Andrew Oung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angel</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01</td>\n",
       "      <td>2010-Q1</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        company_name company_category_code company_country_code  \\\n",
       "50000        NuORDER               fashion                  USA   \n",
       "50001         ChaCha           advertising                  USA   \n",
       "50002        Binfire              software                  USA   \n",
       "50003        Binfire              software                  USA   \n",
       "50004  Unified Color              software                  USA   \n",
       "\n",
       "      company_state_code company_region         company_city    investor_name  \\\n",
       "50000                 CA    Los Angeles       West Hollywood  Mortimer Singer   \n",
       "50001                 IN   Indianapolis               Carmel  Morton Meyerson   \n",
       "50002                 FL    Bocat Raton          Bocat Raton      Moshe Ariel   \n",
       "50003                 FL    Bocat Raton          Bocat Raton      Moshe Ariel   \n",
       "50004                 CA         SF Bay  South San Frnacisco  Mr. Andrew Oung   \n",
       "\n",
       "       investor_country_code  investor_state_code investor_region  \\\n",
       "50000                    NaN                  NaN         unknown   \n",
       "50001                    NaN                  NaN         unknown   \n",
       "50002                    NaN                  NaN         unknown   \n",
       "50003                    NaN                  NaN         unknown   \n",
       "50004                    NaN                  NaN         unknown   \n",
       "\n",
       "       investor_city funding_round_type   funded_at funded_month  \\\n",
       "50000            NaN           series-a  2012-10-01      2012-10   \n",
       "50001            NaN           series-b  2007-10-01      2007-10   \n",
       "50002            NaN              angel  2008-04-18      2008-04   \n",
       "50003            NaN              angel  2010-01-01      2010-01   \n",
       "50004            NaN              angel  2010-01-01      2010-01   \n",
       "\n",
       "      funded_quarter  funded_year  raised_amount_usd  \n",
       "50000        2012-Q4         2012          3060000.0  \n",
       "50001        2007-Q4         2007         12000000.0  \n",
       "50002        2008-Q2         2008           500000.0  \n",
       "50003        2010-Q1         2010           750000.0  \n",
       "50004        2010-Q1         2010                NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see a few rows of a chunk\n",
    "chunk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split columns up into categories\n",
    "useful_cols = ['company_category_code', 'company_country_code',\n",
    "               'company_state_code', 'company_region', 'company_city', \n",
    "               'investor_name', 'investor_category_code', \n",
    "               'investor_country_code', 'investor_state_code',\n",
    "               'investor_city', 'funding_round_type', 'funded_at',\n",
    "               'raised_amount_usd']\n",
    "to_dat_cols = ['funded_at']\n",
    "to_cat_cols = ['investor_category_code', 'funding_round_type', \n",
    "               'investor_region', 'investor_name', 'company_category_code', \n",
    "               'investor_state_code', 'company_country_code', 'company_region', \n",
    "               'investor_city', 'company_city', 'investor_country_code', \n",
    "               'company_state_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cat cols\n",
    "to_cat_cols_dict = {}\n",
    "\n",
    "# turn them into cat\n",
    "for c in to_cat_cols:\n",
    "    to_cat_cols_dict[c] = 'category'\n",
    "\n",
    "# float32\n",
    "to_cat_cols_dict[\"raised_amount_usd\"] = 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make function so we don't have to re read\n",
    "def refined_read_data_in_chunk():\n",
    "    df_iter = pd.read_csv(\"crunchbase-investments.csv\", encoding='latin1', chunksize=5000, usecols=useful_cols, parse_dates=to_dat_cols, dtype=to_cat_cols_dict)\n",
    "    return df_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem (MB):  0.40534114837646484\n",
      "Mem (MB):  0.31264781951904297\n",
      "Mem (MB):  0.30964183807373047\n",
      "Mem (MB):  0.28026294708251953\n",
      "Mem (MB):  0.3034811019897461\n",
      "Mem (MB):  0.3014860153198242\n",
      "Mem (MB):  0.3132619857788086\n",
      "Mem (MB):  0.3039083480834961\n",
      "Mem (MB):  0.3341970443725586\n",
      "Mem (MB):  0.4111642837524414\n",
      "Mem (MB):  0.2430419921875\n",
      "Total Mem (MB):  3.518434524536133\n",
      "\n",
      "dtypes:  company_category_code           category\n",
      "company_country_code            category\n",
      "company_state_code              category\n",
      "company_region                  category\n",
      "company_city                    category\n",
      "investor_name                   category\n",
      "investor_category_code          category\n",
      "investor_country_code           category\n",
      "investor_state_code             category\n",
      "investor_city                   category\n",
      "funding_round_type              category\n",
      "funded_at                 datetime64[ns]\n",
      "raised_amount_usd                float32\n",
      "dtype: object\n",
      "\n",
      "columns:  ['company_category_code', 'company_country_code', 'company_state_code', 'company_region', 'company_city', 'investor_name', 'investor_category_code', 'investor_country_code', 'investor_state_code', 'investor_city', 'funding_round_type', 'funded_at', 'raised_amount_usd']\n"
     ]
    }
   ],
   "source": [
    "# re read using function\n",
    "df_iter = refined_read_data_in_chunk()\n",
    "\n",
    "# total mem holder\n",
    "total_mem = 0\n",
    "\n",
    "# for each chunk\n",
    "for i, df in enumerate(df_iter):\n",
    "    \n",
    "    # get the mem fp\n",
    "    mem = df.memory_usage(deep=True).sum()/(1024*1024)\n",
    "    total_mem += mem\n",
    "    print(\"Mem (MB): \", mem)\n",
    "    \n",
    "# show the total as well\n",
    "print(\"Total Mem (MB): \", total_mem)\n",
    "\n",
    "# read in a second time for cols\n",
    "df_iter = refined_read_data_in_chunk()\n",
    "\n",
    "# show types\n",
    "for df in df_iter:\n",
    "    print(\"\\ndtypes: \", df.dtypes)\n",
    "    print(\"\\ncolumns: \", df.columns.tolist())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even without \"normal\" analysis, we can do a lot with just looking at data types and memory! Now that we have all of these conversions and optimal changes though, we can begin to use a SQL database..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunks into SQLite\n",
    "Now we're in good shape to start exploring and analyzing the data. The next step is to load each chunk into a table in a SQLite database so we can query the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    cid                    name       type  notnull dflt_value  pk\n",
      "0     0   company_category_code       TEXT        0       None   0\n",
      "1     1    company_country_code       TEXT        0       None   0\n",
      "2     2      company_state_code       TEXT        0       None   0\n",
      "3     3          company_region       TEXT        0       None   0\n",
      "4     4            company_city       TEXT        0       None   0\n",
      "5     5           investor_name       TEXT        0       None   0\n",
      "6     6  investor_category_code       TEXT        0       None   0\n",
      "7     7   investor_country_code       TEXT        0       None   0\n",
      "8     8     investor_state_code       TEXT        0       None   0\n",
      "9     9           investor_city       TEXT        0       None   0\n",
      "10   10      funding_round_type       TEXT        0       None   0\n",
      "11   11               funded_at  TIMESTAMP        0       None   0\n",
      "12   12       raised_amount_usd       REAL        0       None   0\n"
     ]
    }
   ],
   "source": [
    "# get sqlite and connect\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('crunch.db')\n",
    "\n",
    "# read in\n",
    "df_iter = refined_read_data_in_chunk()\n",
    "\n",
    "# for each chunk append to table (or create first time)\n",
    "for df in df_iter:\n",
    "    df.to_sql(\"crunch_table\", conn, if_exists='append', index=False)\n",
    "\n",
    "# print results of tables\n",
    "results_df = pd.read_sql('PRAGMA table_info(crunch_table);', conn)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: wc [OPTION]... [FILE]...\n",
      "  or:  wc [OPTION]... --files0-from=F\n",
      "Print newline, word, and byte counts for each FILE, and a total line if\n",
      "more than one FILE is specified.  With no FILE, or when FILE is -,\n",
      "read standard input.  A word is a non-zero-length sequence of characters\n",
      "delimited by white space.\n",
      "The options below may be used to select which counts are printed, always in\n",
      "the following order: newline, word, character, byte, maximum line length.\n",
      "  -c, --bytes            print the byte counts\n",
      "  -m, --chars            print the character counts\n",
      "  -l, --lines            print the newline counts\n",
      "      --files0-from=F    read input from the files specified by\n",
      "                           NUL-terminated names in file F;\n",
      "                           If F is - then read names from standard input\n",
      "  -L, --max-line-length  print the length of the longest line\n",
      "  -w, --words            print the word counts\n",
      "      --help     display this help and exit\n",
      "      --version  output version information and exit\n",
      "\n",
      "Report wc bugs to bug-coreutils@gnu.org\n",
      "GNU coreutils home page: <http://www.gnu.org/software/coreutils/>\n",
      "General help using GNU software: <http://www.gnu.org/gethelp/>\n",
      "For complete documentation, run: info coreutils 'wc invocation'\n",
      "5795840 crunch.db\n"
     ]
    }
   ],
   "source": [
    "# we can use this to see the size of the db\n",
    "!wc --help\n",
    "!wc -c crunch.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MB for crunch.db: 5.52734375\n"
     ]
    }
   ],
   "source": [
    "# convert to mb\n",
    "print(\"Total MB for crunch.db:\", 5795840/1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have everything neatly (as possible) in our db, we can do some inital exploration and analysis on some basic questions as an example..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Analysis\n",
    "We can use the pandas SQLite workflow to analyze startup investments. Also note to remember that each row isn't a unique company, but a unique investment from a single investor. This means that many startups will span multiple rows.\n",
    "\n",
    "This is a data engineering project, but we can still answer some basic example questions such as:\n",
    "* What proportion of the total amount of funds did the top 10% raise? What about the top 1%? Compare these values to the proportions the bottom 10% and bottom 1% raised.\n",
    "* Which category of company attracted the most investments?\n",
    "* Which investor contributed the most money (across all startups)?\n",
    "* Which investors contributed the most money per startup?\n",
    "* Which funding round was the most popular? Which was the least popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  company_category_code      investor_name  raised_amount_usd  \\\n",
      "0           advertising  1-800-FLOWERS.COM          2000000.0   \n",
      "1                  news        10Xelerator            20000.0   \n",
      "2             messaging        10Xelerator            20000.0   \n",
      "3              software        10Xelerator            20000.0   \n",
      "4                   web        10Xelerator            20000.0   \n",
      "\n",
      "  funding_round_type  \n",
      "0           series-a  \n",
      "1              other  \n",
      "2              other  \n",
      "3              angel  \n",
      "4              other  \n"
     ]
    }
   ],
   "source": [
    "# get a \"df\" from the db and display\n",
    "crunch_df = pd.read_sql('select company_category_code, investor_name, raised_amount_usd, funding_round_type from crunch_table;', conn)\n",
    "print(crunch_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       raised_amount_usd\n",
      "company_category_code                   \n",
      "biotech                     1.103964e+11\n",
      "software                    7.308452e+10\n",
      "mobile                      6.477738e+10\n",
      "cleantech                   5.270523e+10\n",
      "enterprise                  4.586093e+10\n"
     ]
    }
   ],
   "source": [
    "# sort by amount raised\n",
    "cmp_type_df = crunch_df.groupby(crunch_df.company_category_code).sum()\n",
    "cmp_type_df.sort_values('raised_amount_usd', ascending=False, inplace=True) \n",
    "print(cmp_type_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  raised_amount_usd\n",
      "investor_name                                      \n",
      "Kleiner Perkins Caufield & Byers       1.121783e+10\n",
      "New Enterprise Associates              9.692542e+09\n",
      "Accel Partners                         6.472126e+09\n",
      "Goldman Sachs                          6.375459e+09\n",
      "Sequoia Capital                        6.039402e+09\n"
     ]
    }
   ],
   "source": [
    "# sort by investor contirbutions\n",
    "investor_name_df = crunch_df.groupby(crunch_df.investor_name).sum()\n",
    "investor_name_df.sort_values('raised_amount_usd', ascending=False, inplace=True) \n",
    "print(investor_name_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  raised_amount_usd  count  avg investment\n",
      "investor_name                                                             \n",
      "Kleiner Perkins Caufield & Byers       1.121783e+10    393    2.854409e+07\n",
      "New Enterprise Associates              9.692542e+09    445    2.178099e+07\n",
      "Accel Partners                         6.472126e+09    322    2.009977e+07\n",
      "Goldman Sachs                          6.375459e+09    123    5.183300e+07\n",
      "Sequoia Capital                        6.039402e+09    369    1.636694e+07\n"
     ]
    }
   ],
   "source": [
    "# sort by investor per startup\n",
    "investor_name_counts = crunch_df.investor_name.value_counts()\n",
    "investor_name_df[\"count\"] = investor_name_counts\n",
    "investor_name_df[\"avg investment\"] = investor_name_df['raised_amount_usd'] / investor_name_df[\"count\"] \n",
    "investor_name_df.sort_values('raised_amount_usd', ascending=False, inplace=True) \n",
    "print(investor_name_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           count\n",
      "series-a   13938\n",
      "series-c+  10870\n",
      "angel       8989\n",
      "venture     8917\n",
      "series-b    8794\n",
      "                count\n",
      "series-b         8794\n",
      "other             964\n",
      "private-equity    357\n",
      "post-ipo           33\n",
      "crowdfunding        5\n"
     ]
    }
   ],
   "source": [
    "# sort by funding rounds\n",
    "funding_round_type_counts = crunch_df.funding_round_type.value_counts()\n",
    "funding_round_type_df = pd.DataFrame()\n",
    "funding_round_type_df['count'] = funding_round_type_counts\n",
    "funding_round_type_df.sort_values('count', ascending=False, inplace=True) \n",
    "\n",
    "# most popular\n",
    "print(funding_round_type_df.head())\n",
    "\n",
    "# least popular\n",
    "print(funding_round_type_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all of the code displayed above, we can easily make out answers to our questions such as proportions of funds (very lopsided, as expected), which category attracts the most investments (biotech), which investor contributed the most money as well as most oney per startup (both Kleiner Perkins Caufield & Byers), and even which funding rounds were most and least popular (series-a and crowfunding, respectively). Using a SQLite workflow, any analysis inside a db can be just as easy as using a pandas df!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis / Next Steps\n",
    "Even though all we have left to do now is just upkeeping our db and researching more topics, it really is an open ended question. We can analyze infinite angles, and its usually up to the discretion of the employer. There are a few things to make notes on though for practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stricter Memory Constraints\n",
    "Ever try to make things as hard as possible for the fun of it? Of course, this doesn't make sense at all in practice, but you may be left with an outdated machine to work with in a pinch someday, so it's nice to know how it works.\n",
    "\n",
    "Luckily for us, all this really means is changing up the chunk size! Although this creates more chunks, the robustness of our loops don't really hard code the max number of chunks, so we can play around to see which chunk size would get us to memory footprints of say, under 1 mb.\n",
    "\n",
    "Even if we were not limited to strict memory contraints, finding the optimal size is important enough anyway that you should always try to find the smallest possible footprint for each chunk that makes sense (you still don't want a million chunks of minimal size)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Crunchbase Datasets\n",
    "Using the same Github link at the beginning of the project, we can find other datasets on Crunchbase, spanning different times, or even different topics altogether (https://github.com/datahoarder/crunchbase-october-2013).\n",
    "\n",
    "ALthough most of this analysis will be the same and redundant, some things that we can do are: \n",
    "* Understand which columns the data sets share, and how the data sets are linked.\n",
    "* Create a relational database design that links the data sets together and reduces the overall disk space the database file consumes.\n",
    "* Use pandas to populate each table in the database, create the appropriate indexes, and so on.\n",
    "\n",
    "This is ultimately just designing our own database at this point, and more information on this can be found in other projects in the Github repo. Seeing how different datasets can interact with each other in the form of tables is simple yet interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "To sum everything up, we practiced some memory constraints in this project to build up from a basic dataset to a SQLite workflow in order to answer some analysis questions. It turns out that there is a lot more to data than we think!\n",
    "\n",
    "A lot of the time people overlook the 'boring' aspects of data science, and the subfield of data engineering really brings these topics into the light. Even though they may not be as interesting as building machine learning models, they are still just as important.\n",
    "\n",
    "Being an expert in both fields may save you one day from an unlikely "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
